{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rESKRJKu4NUc",
        "outputId": "e9fece2f-0276-4507-b188-9dab7cd70c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vtOb4Bwomu2P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rB-iOLJ9tVD"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wNDe9zGPrKkA"
      },
      "outputs": [],
      "source": [
        "SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "MAX_TRAIN_IMAGES = 300\n",
        "IMAGE_COUNT = 600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KfY2aunkppW2"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path):\n",
        "  image_string = tf.io.read_file(image_path)\n",
        "  image_tensor = tf.image.decode_jpeg(image_string, channels=3)\n",
        "  resized_tensor = tf.image.resize(image_tensor, [SIZE, SIZE])\n",
        "  resized_tensor = tf.cast(resized_tensor, dtype=tf.float32) / 255.0\n",
        "  return resized_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BgBr1qRb-KgO"
      },
      "outputs": [],
      "source": [
        "def load_data(low_res_image_path, high_res_image_path):\n",
        "  low_res_image = read_image(low_res_image_path)\n",
        "  high_res_image = read_image(high_res_image_path)\n",
        "  return low_res_image, high_res_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NBbBpORjvsgr"
      },
      "outputs": [],
      "source": [
        "def get_dataset(low_res_images, high_res_images):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((low_res_images, high_res_images))\n",
        "  dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMuHuyrXszc0",
        "outputId": "87bfa82a-7fbf-4d63-9dcb-3e53f9e92ffe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3762/3762 [00:00<00:00, 678461.18it/s]\n",
            "100%|██████████| 600/600 [00:00<00:00, 1484.58it/s]\n",
            "2023-03-29 22:57:21.476045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "low_res = glob('/Applications/ML projects/Failures/Super Resolution/low res/*')\n",
        "high_res = glob('/Applications/ML projects/Failures/Super Resolution/high res/*')\n",
        "\n",
        "_2 = []\n",
        "_4 = []\n",
        "_6 = []\n",
        "\n",
        "for lrfile in tqdm(low_res):\n",
        "  image_type = lrfile.split('/')[-1]\n",
        "  image_res = image_type.split('_')[-1]\n",
        "  if image_res == '2.jpg':\n",
        "    _2.append(lrfile)\n",
        "  elif image_res == '4.jpg':\n",
        "    _4.append(lrfile)\n",
        "  elif image_res == '6.jpg':\n",
        "    _6.append(lrfile)\n",
        "\n",
        "_2 = sorted(_2)[:IMAGE_COUNT]\n",
        "_4 = sorted(_4)[:IMAGE_COUNT]\n",
        "_6 = sorted(_6)[:IMAGE_COUNT]\n",
        "\n",
        "_high_res = []\n",
        "for lr_file in tqdm(_2):\n",
        "  lr_image_type = lr_file.split('/')[-1]\n",
        "  lr_image_res = lr_image_type.split('_')[0]\n",
        "  for hr_file in high_res:\n",
        "    hr_image_type = hr_file.split('/')[-1]\n",
        "    hr_image_res = hr_image_type.split('.')[0]\n",
        "    if hr_image_res == lr_image_res:\n",
        "      _high_res.append(hr_file)\n",
        "\n",
        "_2_train, _2_val = _2[:MAX_TRAIN_IMAGES], _2[MAX_TRAIN_IMAGES:]\n",
        "_4_train, _4_val = _4[:MAX_TRAIN_IMAGES], _4[MAX_TRAIN_IMAGES:]\n",
        "_6_train, _6_val = _6[:MAX_TRAIN_IMAGES], _6[MAX_TRAIN_IMAGES:]\n",
        "high_res_train, high_res_val = _high_res[:MAX_TRAIN_IMAGES], _high_res[MAX_TRAIN_IMAGES:]\n",
        "\n",
        "train_dataset_24 = get_dataset(_2_train, _4_train)\n",
        "train_dataset_46 = get_dataset(_4_train, _6_train)\n",
        "train_dataset_6h = get_dataset(_6_train, high_res_train)\n",
        "\n",
        "val_dataset_24 = get_dataset(_2_val, _4_val)\n",
        "val_dataset_46 = get_dataset(_4_val, _6_val)\n",
        "val_dataset_6h = get_dataset(_6_val, high_res_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fqeYvzi0edO",
        "outputId": "7c90fcd6-d6ba-46fe-fcf6-baec9d6bdb80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset_24)\n",
        "print(val_dataset_24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk8gfs3W0kiS",
        "outputId": "f1e45bc2-5881-49f3-e11a-698f6abe2839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset_46)\n",
        "print(val_dataset_46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfgPwDdj0npy",
        "outputId": "245b4ea8-5186-4f5b-8cf1-14b9d6255fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset_6h)\n",
        "print(val_dataset_6h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HsM9IUF_HWs"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9B6GV4mE_GVM"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Add, GlobalAveragePooling2D, Conv2D, Concatenate, MaxPooling2D, UpSampling2D, Input\n",
        "from keras import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVmFfnRL_duj"
      },
      "source": [
        "Selective Kernel Feature Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yahp0aCq_Xqh"
      },
      "outputs": [],
      "source": [
        "def selective_kernel_feature_fusion(multi_scale_feature1, multi_scale_feature2, multi_scale_feature3):\n",
        "  channels = list(multi_scale_feature1.shape)[-1]\n",
        "  combined_feature = Add()(\n",
        "      [multi_scale_feature1, multi_scale_feature2, multi_scale_feature3]\n",
        "  )\n",
        "  gap = GlobalAveragePooling2D()(combined_feature)\n",
        "  channel_wise_statistics = tf.reshape(gap, shape=(-1, 1, 1, channels))\n",
        "  compact_feature_representation = Conv2D(\n",
        "      filters=channels // 8, kernel_size=(1, 1), activation='relu'\n",
        "  )(channel_wise_statistics)\n",
        "  feature_descriptor1 = Conv2D(channels, kernel_size=(1, 1), activation='softmax')(compact_feature_representation)\n",
        "  feature_descriptor2 = Conv2D(channels, kernel_size=(1, 1), activation='softmax')(compact_feature_representation)\n",
        "  feature_descriptor3 = Conv2D(channels, kernel_size=(1, 1), activation='softmax')(compact_feature_representation)\n",
        "  feature1 = multi_scale_feature1 * feature_descriptor1\n",
        "  feature2 = multi_scale_feature2 * feature_descriptor2\n",
        "  feature3 = multi_scale_feature3 * feature_descriptor3\n",
        "  aggregate_feature = Add()([feature1, feature2, feature3])\n",
        "  return aggregate_feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3JKyU5a_kji"
      },
      "source": [
        "Dual Attention Unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NsXUfYgB_bWc"
      },
      "outputs": [],
      "source": [
        "def channel_attention_block(input_tensor):\n",
        "  channels = list(input_tensor.shape)[-1]\n",
        "  gap = GlobalAveragePooling2D()(input_tensor)\n",
        "  feature_descriptor = tf.reshape(gap, shape=(-1, 1, 1, channels))\n",
        "  feature_activations = Conv2D(\n",
        "      filters=channels // 8, kernel_size=(1, 1), activation='relu'\n",
        "  )(feature_descriptor)\n",
        "  feature_activations = Conv2D(\n",
        "      filters=channels, kernel_size=(1, 1), activation='sigmoid'\n",
        "  )(feature_activations)\n",
        "  return input_tensor * feature_activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UmG6uCYZ_oS2"
      },
      "outputs": [],
      "source": [
        "def spatial_attention_block(input_tensor):\n",
        "  average_pooling = tf.reduce_mean(input_tensor, axis=-1)\n",
        "  average_pooling = tf.expand_dims(average_pooling, axis=-1)\n",
        "  max_pooling = tf.reduce_max(input_tensor, axis=-1)\n",
        "  max_pooling = tf.expand_dims(max_pooling, axis=-1)\n",
        "  concatenated = Concatenate(axis=-1)([average_pooling, max_pooling])\n",
        "  feature_map = Conv2D(1, kernel_size=(1, 1))(concatenated)\n",
        "  feature_map = tf.nn.sigmoid(feature_map)\n",
        "  return input_tensor * feature_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IOjHhirl_qZ4"
      },
      "outputs": [],
      "source": [
        "def dual_attention_unit_block(input_tensor):\n",
        "  channels = list(input_tensor.shape)[-1]\n",
        "  feature_map = Conv2D(\n",
        "      channels, kernel_size=(3, 3), padding='same', activation='relu'\n",
        "  )(input_tensor)\n",
        "  feature_map = Conv2D(\n",
        "      channels, kernel_size=(3, 3), padding='same'\n",
        "  )(feature_map)\n",
        "\n",
        "  channel_attention = channel_attention_block(feature_map)\n",
        "  spatial_attention = spatial_attention_block(feature_map)\n",
        "  concatenation = Concatenate(axis=-1)([channel_attention, spatial_attention])\n",
        "  concatenation = Conv2D(channels, kernel_size=(1, 1))(concatenation)\n",
        "\n",
        "  return Add()([input_tensor, concatenation])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7vlXL0u_uiI"
      },
      "source": [
        "Multi Scale Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CstdnB4o_s1z"
      },
      "outputs": [],
      "source": [
        "def down_sampling_block(input_tensor):\n",
        "  channels = list(input_tensor.shape)[-1]\n",
        "  main_branch = Conv2D(channels, kernel_size=(1, 1), activation='relu')(input_tensor)\n",
        "  main_branch = Conv2D(channels, kernel_size=(3, 3), padding='same', activation='relu')(main_branch)\n",
        "  main_branch = MaxPooling2D()(main_branch)\n",
        "  main_branch = Conv2D(channels * 2, kernel_size=(1, 1))(main_branch)\n",
        "  skip_branch = MaxPooling2D()(input_tensor)\n",
        "  skip_branch = Conv2D(channels * 2, kernel_size=(1, 1))(skip_branch)\n",
        "  return Add()([main_branch, skip_branch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JCC11-Zv_1A7"
      },
      "outputs": [],
      "source": [
        "def up_sampling_block(input_tensor):\n",
        "  channels = list(input_tensor.shape)[-1]\n",
        "  main_branch = Conv2D(channels, kernel_size=(1, 1), activation='relu')(input_tensor)\n",
        "  main_branch = Conv2D(channels, kernel_size=(3, 3), padding='same', activation='relu')(main_branch)\n",
        "  main_branch = UpSampling2D()(main_branch)\n",
        "  main_branch = Conv2D(channels // 2, kernel_size=(1, 1))(main_branch)\n",
        "  skip_branch = UpSampling2D()(input_tensor)\n",
        "  skip_branch = Conv2D(channels // 2, kernel_size=(1, 1))(skip_branch)\n",
        "  return Add()([main_branch, skip_branch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XI9CDVqF_2_7"
      },
      "outputs": [],
      "source": [
        "def multi_scale_residual_block(input_tensor, channels):\n",
        "  feature1 = input_tensor\n",
        "  feature2 = down_sampling_block(feature1)\n",
        "  feature3 = down_sampling_block(feature2)\n",
        "\n",
        "  feature1_dau1 = dual_attention_unit_block(feature1)\n",
        "  feature2_dau1 = dual_attention_unit_block(feature2)\n",
        "  feature3_dau1 = dual_attention_unit_block(feature3)\n",
        "\n",
        "  skff1 = selective_kernel_feature_fusion(\n",
        "      feature1_dau1,\n",
        "      up_sampling_block(feature2_dau1),\n",
        "      up_sampling_block(up_sampling_block(feature3_dau1))\n",
        "  )\n",
        "\n",
        "  skff2 = selective_kernel_feature_fusion(\n",
        "      down_sampling_block(feature1_dau1),\n",
        "      feature2_dau1,\n",
        "      up_sampling_block(feature3_dau1)\n",
        "  )\n",
        "\n",
        "  skff3 = selective_kernel_feature_fusion(\n",
        "      down_sampling_block(down_sampling_block(feature1_dau1)),\n",
        "      down_sampling_block(feature2_dau1),\n",
        "      feature3_dau1\n",
        "  )\n",
        "\n",
        "  feature1_dau2 = dual_attention_unit_block(skff1)\n",
        "  feature2_dau2 = up_sampling_block(dual_attention_unit_block(skff2))\n",
        "  feature3_dau2 = up_sampling_block(up_sampling_block(dual_attention_unit_block(skff3)))\n",
        "\n",
        "  skff_ = selective_kernel_feature_fusion(feature1_dau2, feature2_dau2, feature3_dau2)\n",
        "  feature = Conv2D(channels, kernel_size=(3, 3), padding='same')(skff_)\n",
        "\n",
        "  return Add()([input_tensor, feature])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5SHcaqAEE6"
      },
      "source": [
        "MIRNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Q1sJ2ALk_6HG"
      },
      "outputs": [],
      "source": [
        "def recursive_residual_block(input_tensor, msrb_count, channels):\n",
        "  x = Conv2D(channels, kernel_size=(3, 3), padding='same')(input_tensor)\n",
        "  for _ in range(msrb_count):\n",
        "    x = multi_scale_residual_block(x, channels)\n",
        "  x = Conv2D(channels, kernel_size=(3, 3), padding='same')(x)\n",
        "  return Add()([input_tensor, x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o-1gOlIDAHNy"
      },
      "outputs": [],
      "source": [
        "def MIRNet_Model(rrb_count, msrb_count, channels):\n",
        "  input_tensor = Input(shape=(None, None, 3))\n",
        "  x = Conv2D(channels, kernel_size=(3, 3), padding='same')(input_tensor)\n",
        "  for _ in range(rrb_count):\n",
        "    x = recursive_residual_block(x, msrb_count, channels)\n",
        "  x = Conv2D(3, kernel_size=(3, 3), padding='same')(x)\n",
        "  output_tensor = Add()([input_tensor, x])\n",
        "  return Model(input_tensor, output_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igIpsujbAKU3"
      },
      "source": [
        "Build Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kO9rT0HUAJSi"
      },
      "outputs": [],
      "source": [
        "RRB_COUNT = 3\n",
        "MSRB_COUNT = 2\n",
        "CHANNELS = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tko_UrKZARb5"
      },
      "outputs": [],
      "source": [
        "model_24 = MIRNet_Model(RRB_COUNT, MSRB_COUNT, CHANNELS)\n",
        "model_46 = MIRNet_Model(RRB_COUNT, MSRB_COUNT, CHANNELS)\n",
        "model_6h = MIRNet_Model(RRB_COUNT, MSRB_COUNT, CHANNELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSoaOp7oAc5_"
      },
      "source": [
        "Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wQOVcNk6Abgk"
      },
      "outputs": [],
      "source": [
        "def charbonnier_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.sqrt(tf.square(y_true - y_pred) + tf.square(1e-3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3DAwrUv9Agzp"
      },
      "outputs": [],
      "source": [
        "def peak_signal_noise_ratio(y_true, y_pred):\n",
        "    return tf.image.psnr(y_pred, y_true, max_val=255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fRTS6OFCAi_P"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8h8Nt2doBD7g"
      },
      "outputs": [],
      "source": [
        "model_24.compile(optimizer=optimizer, loss=charbonnier_loss, metrics=[peak_signal_noise_ratio])\n",
        "model_46.compile(optimizer=optimizer, loss=charbonnier_loss, metrics=[peak_signal_noise_ratio])\n",
        "model_6h.compile(optimizer=optimizer, loss=charbonnier_loss, metrics=[peak_signal_noise_ratio])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0-jRVCEbBLPh",
        "outputId": "6626eafd-0e13-4de2-9d7d-f79b55ea8dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        }
      ],
      "source": [
        "history_24 = model_24.fit(\n",
        "    train_dataset_24,\n",
        "    validation_data=val_dataset_24,\n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=\"val_peak_signal_noise_ratio\",\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "            min_delta=1e-7,\n",
        "            mode=\"max\",\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbiokWWXBftz"
      },
      "outputs": [],
      "source": [
        "model_24.save('model_24.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9clSgErBa8n"
      },
      "outputs": [],
      "source": [
        "history_46 = model_46.fit(\n",
        "    train_dataset_46,\n",
        "    validation_data=val_dataset_46,\n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=\"val_peak_signal_noise_ratio\",\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "            min_delta=1e-7,\n",
        "            mode=\"max\",\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZh07XOpBv8X"
      },
      "outputs": [],
      "source": [
        "model_46.save('model_46.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rKRaN47Ba1U"
      },
      "outputs": [],
      "source": [
        "history_6h = model_6h.fit(\n",
        "    train_dataset_6h,\n",
        "    validation_data=val_dataset_6h,\n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=\"val_peak_signal_noise_ratio\",\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "            min_delta=1e-7,\n",
        "            mode=\"max\",\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4znhE7XB0ef"
      },
      "outputs": [],
      "source": [
        "model_6h.save('model_6h.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
