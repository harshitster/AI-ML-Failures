{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KXTyLxi5qKvV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuHJ_ju5qscg"
      },
      "source": [
        "CSV data path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lHZiY_JIqeCb"
      },
      "outputs": [],
      "source": [
        "data = '/Applications/ML projects/Song Lyrics/Dataset - 2/archive/csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOWYmImtqv9v"
      },
      "source": [
        "Read lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OS6FSc79qi9c"
      },
      "outputs": [],
      "source": [
        "def readLyrics(data):\n",
        "  lyrics = []\n",
        "  for CSV_FILE in tqdm(os.listdir(data)):\n",
        "    CSV_PATH = os.path.join(data, CSV_FILE)\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    df = df.dropna()\n",
        "    dfLyrics = df['Lyric'].values\n",
        "    for lyric in dfLyrics:\n",
        "      lyrics.append(lyric)\n",
        "\n",
        "  return lyrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJIGV5KmtVoq",
        "outputId": "852a8ee7-31bb-4d76-c5ab-487a47b2a85d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 64.29it/s]\n"
          ]
        }
      ],
      "source": [
        "lyrics = readLyrics(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QF7RDFvtvZO"
      },
      "source": [
        "Clean lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "37xgXaTStw62"
      },
      "outputs": [],
      "source": [
        "def cleanLyrics(lyrics):\n",
        "  for i in tqdm(range(len(lyrics))):\n",
        "    lyric = lyrics[i]\n",
        "    lyric = lyric.lower()\n",
        "    lyric = lyric.replace('[^A-Za-z]', '')\n",
        "    lyric = lyric.replace('\\s+', ' ')\n",
        "    lyric = 'start  ' + \" \".join([word for word in lyric.split() if len(word) > 1]) + '  end'\n",
        "    lyrics[i] = lyric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "-WntS1wGufmr",
        "outputId": "d4018045-f36c-4306-fe09-33da239cf3bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Tudo o que eu quero nessa vida,\\nToda vida, é\\nÉ amar você\\nAmar você\\n\\nO seu amor é como uma chama acesa\\nQueima de prazer\\nDe prazer\\n\\nEu já falei com Deus que não vou te deixar\\nVou te levar pra onde for\\nQualquer lugar\\nJá fiz de tudo pra não te perder\\n\\nArerê,\\nUm lobby, um hobby, um love com você\\nArerê,\\nUm lobby, um hobby, um love com você\\n\\nCai, cai, cai, cai, cai pra cá\\nHey, hey, hey\\nTu-do,tu-do, vai rolar'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lyrics[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV0PIMi5ug31",
        "outputId": "02cb8d76-982d-404d-f17a-7f98c371dfad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3422/3422 [00:00<00:00, 13927.16it/s]\n"
          ]
        }
      ],
      "source": [
        "cleanLyrics(lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "BEMlZV9mumRq",
        "outputId": "b4015304-7bb6-441c-e797-43cd538b2f15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"start  one one one one one talkin' in my sleep at night makin' myself crazy out of my mind out of my mind wrote it down and read it out hopin' it would save me too many times too many times refrain my love he makes me feel like nobody else nobody else but my love he doesn't love me so tell myself tell myself pre one don't pick up the phone you know he's only callin' 'cause he's drunk and alone two don't let him in you'll have to kick him out again three don't be his friend you know you're gonna wake up in his bed in the morning and if you're under him you ain't gettin' over him got new rules count 'em got new rules count 'em gotta tell them to myself got new rules count 'em gotta tell them to myself keep pushin' forwards but he keeps pullin' me backwards nowhere to turn no way nowhere to turn no now i'm standin' back from it finally see the pattern never learn never learn refrain but my love he doesn't love me so tell myself tell myself do do do pre one don't pick up the phone you know he's only callin' 'cause he's drunk and alone two don't let him in you'll have to kick him out again three don't be his friend you know you're gonna wake up in his bed in the morning and if you're under him you ain't gettin' over him got new rules count 'em got new rules count 'em gotta tell them to myself got new rules count 'em gotta tell them to myself practice makes perfect i'm still tryna learn it by heart got new rules count 'em eat sleep and breathe it rehearse and repeat it 'cause got new pre one don't pick up the phone yeah you know he's only callin' 'cause he's drunk and alone alone two don't let him in uhooh you'll have to kick him out again again three don't be his friend you know you're gonna wake up in his bed in the morning and if you're under him you ain't gettin' over him got new rules count 'em got new rules count 'em whoaooh whoaooh whoa gotta tell them to myself got new rules count 'em baby you know count 'em gotta tell them to myself don't let him in don't let him in don't don't don't don't don't be his friend don't be his friend don't don't don't don't don't let him in don't let him in don't don't don't don't don't be his friend don't be his friend don't don't don't don't you're gettin' over him  end\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lyrics[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlYWj-kPuwIx",
        "outputId": "a9e19452-0ba7-4e64-b032-f758aadbf89d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3422"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9qPCfCKru9Fx"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqi6PMAwvGko",
        "outputId": "6dd7a373-a3cf-4958-e488-1c8219d1617e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44888"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lyrics)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47TtxbBsvQs_",
        "outputId": "8174db4d-1215-4193-c1b8-4b15193fff0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5287"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length = max(len(lyric.split()) for lyric in lyrics)\n",
        "max_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkrZReaPvp21"
      },
      "source": [
        "Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pdo6ME9_vk6j"
      },
      "outputs": [],
      "source": [
        "split = int(len(lyrics) * 0.80)\n",
        "train = lyrics[:split]\n",
        "test = lyrics[split:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "538MuQRcv11d"
      },
      "source": [
        "Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mWK2xdRwwmCQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "syD_qqBev0aC"
      },
      "outputs": [],
      "source": [
        "def dataGenerator(lyrics, tokenizer, max_length, vocab_size, batch_size):\n",
        "  X, y = list(), list()\n",
        "  n = 0\n",
        "  while 1:\n",
        "    for lyric in lyrics:\n",
        "      n += 1\n",
        "      seq = tokenizer.texts_to_sequences([lyric])[0]\n",
        "      for i in range(len(seq)):\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "        in_seq = pad_sequences([in_seq], maxlen = max_length)[0]\n",
        "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "        X.append(in_seq)\n",
        "        y.append(out_seq)\n",
        "      if n == batch_size:\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        yield X, y\n",
        "        X, y = list(), list()\n",
        "        n = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijKh-xq2yFLl"
      },
      "source": [
        "Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_5G4dNTWyUnp"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HeeTv2okyGmh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-26 12:57:35.687259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "input = Input(shape=(max_length, ))\n",
        "l1 = Embedding(vocab_size, 256, mask_zero=0)(input)\n",
        "l2 = Dropout(0.4)(l1)\n",
        "l3 = LSTM(256)(l2)\n",
        "l4 = Dense(256, activation='relu')(l3)\n",
        "output = Dense(vocab_size, activation='softmax')(l4)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmADvtsozm6S"
      },
      "source": [
        "Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Yg5zKdL1zpev"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "STEPS = len(train) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ADAn-Nvtzzpl"
      },
      "outputs": [],
      "source": [
        "for i in range(EPOCHS):\n",
        "  data_gen = dataGenerator(train, tokenizer, max_length, vocab_size, BATCH_SIZE)\n",
        "  model.fit(data_gen, epochs=1, steps_per_epoch=STEPS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFnykuDQ0b9z"
      },
      "outputs": [],
      "source": [
        "models_path = ''\n",
        "model.save(os.path.join(models_path, 'best_model.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z3yU1Gm0aaQ"
      },
      "source": [
        "Lyric Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YLBAD9r0Jdr"
      },
      "outputs": [],
      "source": [
        "def idxToWord(index, tokenizer):\n",
        "  if index in tokenizer.word_index:\n",
        "    return tokenizer.word_index[index]\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YT6w95V06eO"
      },
      "outputs": [],
      "source": [
        "def predictLyric(model, lyric, tokenizer, max_length):\n",
        "  in_lyric = lyric\n",
        "  split = len(in_lyric)\n",
        "\n",
        "  for i in range(max_length):\n",
        "    sequence = tokenizer.texts_to_sequences([in_lyric])[0]\n",
        "    sequence = pad_sequences([sequence], max_length)\n",
        "    indexes = model.predict([sequence], verbose=0)\n",
        "    index = np.argmax(indexes)\n",
        "    word = idxToWord(index, tokenizer)\n",
        "    if word == None:\n",
        "      break\n",
        "    in_lyric += ' ' + word\n",
        "    if word == 'end':\n",
        "      out_lyric = in_lyric[split:]\n",
        "      return out_lyric\n",
        "\n",
        "  return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otjGVbj53IBW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
